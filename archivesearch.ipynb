{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from whoosh.index import create_in\n",
    "from whoosh.analysis import StandardAnalyzer\n",
    "from whoosh.writing import AsyncWriter\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "import os.path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARXIV = \"arxiv-metadata-oai-snapshot.json\"\n",
    "TEXT = 'text.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "arxiv = open(ARXIV, 'r')\n",
    "ARCSIZE = 1796911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 105.70%"
     ]
    }
   ],
   "source": [
    "arxivList = []\n",
    "cnt = 0\n",
    "for articles in arxiv:\n",
    "    cnt += 1\n",
    "    arxivDict = json.loads(articles)\n",
    "    arxivList.append(arxivDict)\n",
    "    print(\"\\r {0:2.2f}%\".format(cnt/ARCSIZE*100), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00%"
     ]
    }
   ],
   "source": [
    "CORPUS_SIZE = 10000\n",
    "cnt = 0\n",
    "subjPair = []\n",
    "for article in arxivList:\n",
    "    cnt += 1\n",
    "    abstract = article['abstract'].replace(\"\\n\", ' ').replace(r'\\\\'and'$', '').strip()\n",
    "    doc = nlp(abstract)\n",
    "    for sents in doc.sents:\n",
    "        offset = sents[0].i\n",
    "        sentsTextListBK = [token.text for token in sents]\n",
    "#         chunkSet = set()\n",
    "        for chunk in sents.noun_chunks:\n",
    "            if \"subj\" in chunk.root.dep_:\n",
    "                sentsTextList = sentsTextListBK.copy()\n",
    "                sth = chunk[0].i-offset\n",
    "                eth = chunk[-1].i-offset\n",
    "                sentsTextList[sth] = \"<mark>\" + sentsTextList[sth]\n",
    "                sentsTextList[eth] = sentsTextList[eth] + \"</mark>\"\n",
    "                subjHLText = \" \".join(sentsTextList)\n",
    "                subjHLText = re.sub(r' (?=[^\\w|\\(|<])', '', subjHLText)\n",
    "                subjHLText = re.sub(r'(?<=\\[|\\(|-) +', '', subjHLText)\n",
    "                subjPair.append((chunk.text, subjHLText))                \n",
    "#                 chunkSet.add(chunk.text)\n",
    "#         subjHLText = \" \".join(sentsTextList)\n",
    "#         subjHLText = re.sub(r' (?=[^\\w|\\(|<])', '', subjHLText)\n",
    "#         subjHLText = re.sub(r'(?<=\\[|\\(|-) +', '', subjHLText)\n",
    "#         for chunktext in chunkSet:\n",
    "#             subjPair.append((chunktext, subjHLText))\n",
    "\n",
    "    print(\"\\r {0:2.2f}%\".format(cnt/CORPUS_SIZE*100), end='')\n",
    "    if cnt == CORPUS_SIZE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00%"
     ]
    }
   ],
   "source": [
    "schema = Schema(subj=TEXT(stored=True), content=TEXT(stored=True))\n",
    "if not os.path.exists(\"myindex\"):\n",
    "    os.mkdir(\"myindex\")\n",
    "ix = create_in(\"myindex\", schema)\n",
    "writer = ix.writer()\n",
    "cnt = 0\n",
    "pairNum = len(subjPair)\n",
    "for (subjText, sentText) in subjPair:\n",
    "    cnt += 1\n",
    "    writer.add_document(subj=subjText, content=sentText)\n",
    "    print(\"\\r {0:2.2f}%\".format(cnt/pairNum*100), end='')\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchArxiv(key_words, ix=ix):\n",
    "    with ix.searcher() as searcher:\n",
    "        parser = QueryParser(\"subj\", ix.schema)\n",
    "        query = parser.parse(key_words)\n",
    "        results = searcher.search(query, limit=20)\n",
    "        if len(results) != 0:\n",
    "            for result in results:\n",
    "                print(result['content'])\n",
    "        return len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"In this work, we evaluate the lifetimes of the doubly (charmed) baryons \\Xi_{cc}^{+}, \\Xi_{cc}^{++} and \\Omega_{cc}^{+}. We carefully calculate the non-spectator contributions at the quark level where the Cabibbo-suppressed diagrams are also included. The hadronic matrix elements are evaluated in the simple non-relativistic harmonic oscillator model. Our numerical results are generally consistent with that obtained by other authors who used the diquark model. However, all the theoretical predictions on the lifetimes are one order larger than the upper limit set by the recent SELEX measurement. This discrepancy would be clarified by the future experiment, if more accurate experiment still confirms the value of the SELEX collaboration, there must be some unknown mechanism to be explored.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this work, <mark>we</mark> evaluate the lifetimes of the doubly (charmed) baryons\\Xi_{cc}^{+},\\Xi_{cc}^{++} and\\Omega_{cc}^{+}.\n",
      "<mark>We</mark> carefully calculate the non-spectator contributions at the quark level where <mark>the Cabibbo-suppressed diagrams</mark> are also included.\n",
      "<mark>The hadronic matrix elements</mark> are evaluated in the simple non-relativistic harmonic oscillator model.\n",
      "<mark>Our numerical results</mark> are generally consistent with that obtained by other authors <mark>who</mark> used the diquark model.\n",
      "However, <mark>all the theoretical predictions</mark> on the lifetimes are one order larger than the upper limit set by the recent SELEX measurement.\n",
      "<mark>This discrepancy</mark> would be clarified by the future experiment, if <mark>more accurate experiment</mark> still confirms the value of the SELEX collaboration, there must be some unknown mechanism to be explored.\n"
     ]
    }
   ],
   "source": [
    "para = para.replace(r'\\\\'and'$', '')\n",
    "doc = nlp(para)\n",
    "for sents in doc.sents:\n",
    "    off = sents[0].i\n",
    "    sentsTextList = [token.text for token in sents]\n",
    "    for chunk in sents.noun_chunks:\n",
    "        if \"subj\" in chunk.root.dep_:\n",
    "            sth = chunk[0].i-off\n",
    "            eth = chunk[-1].i-off\n",
    "            sentsTextList[sth] = \"<mark>\" + sentsTextList[sth]\n",
    "            sentsTextList[eth] = sentsTextList[eth] + \"</mark>\"\n",
    "    subjHLText = \" \".join(sentsTextList)\n",
    "    subjHLText = re.sub(r' (?=[^\\w|\\(|<])', '', subjHLText)\n",
    "    subjHLText = re.sub(r'(?<=\\[|\\(|-) +', '', subjHLText)\n",
    "    print(subjHLText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
